{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77f1bbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "494fcdfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Resume_str</th>\n",
       "      <th>Resume_html</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16852973</td>\n",
       "      <td>HR ADMINISTRATOR/MARKETING ASSOCIATE\\...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22323967</td>\n",
       "      <td>HR SPECIALIST, US HR OPERATIONS      ...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33176873</td>\n",
       "      <td>HR DIRECTOR       Summary      Over 2...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27018550</td>\n",
       "      <td>HR SPECIALIST       Summary    Dedica...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17812897</td>\n",
       "      <td>HR MANAGER         Skill Highlights  ...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                         Resume_str  \\\n",
       "0  16852973           HR ADMINISTRATOR/MARKETING ASSOCIATE\\...   \n",
       "1  22323967           HR SPECIALIST, US HR OPERATIONS      ...   \n",
       "2  33176873           HR DIRECTOR       Summary      Over 2...   \n",
       "3  27018550           HR SPECIALIST       Summary    Dedica...   \n",
       "4  17812897           HR MANAGER         Skill Highlights  ...   \n",
       "\n",
       "                                         Resume_html Category  \n",
       "0  <div class=\"fontsize fontface vmargins hmargin...       HR  \n",
       "1  <div class=\"fontsize fontface vmargins hmargin...       HR  \n",
       "2  <div class=\"fontsize fontface vmargins hmargin...       HR  \n",
       "3  <div class=\"fontsize fontface vmargins hmargin...       HR  \n",
       "4  <div class=\"fontsize fontface vmargins hmargin...       HR  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this dataset is downloaded from kaggle\n",
    "# https://www.kaggle.com/datasets/snehaanbhawal/resume-dataset\n",
    "df = pd.read_csv(r'../../data/Resume.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "05156499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HR', 'DESIGNER', 'INFORMATION-TECHNOLOGY', 'TEACHER', 'ADVOCATE', 'BUSINESS-DEVELOPMENT', 'HEALTHCARE', 'FITNESS', 'AGRICULTURE', 'BPO', 'SALES', 'CONSULTANT', 'DIGITAL-MEDIA', 'AUTOMOBILE', 'CHEF', 'FINANCE', 'APPAREL', 'ENGINEERING', 'ACCOUNTANT', 'CONSTRUCTION', 'PUBLIC-RELATIONS', 'BANKING', 'ARTS', 'AVIATION']\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "category_list = list(dict.fromkeys(df['Category'].tolist()))\n",
    "print(category_list)\n",
    "print(len(category_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b5797ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2484 entries, 0 to 2483\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   ID           2484 non-null   int64 \n",
      " 1   Resume_str   2484 non-null   object\n",
      " 2   Resume_html  2484 non-null   object\n",
      " 3   Category     2484 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 77.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9614fdfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    HR\n",
       "1    HR\n",
       "2    HR\n",
       "3    HR\n",
       "4    HR\n",
       "Name: Category, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Category'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c0f43a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'ACCOUNTANT',\n",
       " 1: 'ADVOCATE',\n",
       " 2: 'AGRICULTURE',\n",
       " 3: 'APPAREL',\n",
       " 4: 'ARTS',\n",
       " 5: 'AUTOMOBILE',\n",
       " 6: 'AVIATION',\n",
       " 7: 'BANKING',\n",
       " 8: 'BPO',\n",
       " 9: 'BUSINESS-DEVELOPMENT',\n",
       " 10: 'CHEF',\n",
       " 11: 'CONSTRUCTION',\n",
       " 12: 'CONSULTANT',\n",
       " 13: 'DESIGNER',\n",
       " 14: 'DIGITAL-MEDIA',\n",
       " 15: 'ENGINEERING',\n",
       " 16: 'FINANCE',\n",
       " 17: 'FITNESS',\n",
       " 18: 'HEALTHCARE',\n",
       " 19: 'HR',\n",
       " 20: 'INFORMATION-TECHNOLOGY',\n",
       " 21: 'PUBLIC-RELATIONS',\n",
       " 22: 'SALES',\n",
       " 23: 'TEACHER'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df['Resume_str'].tolist()\n",
    "y = df[\"Category\"].astype(\"category\").cat.codes\n",
    "label_map = dict(enumerate(df[\"Category\"].astype(\"category\").cat.categories))\n",
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dd0495a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "43de8737",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0]\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size())\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "def embed_with_e5(texts, model, tokenizer):\n",
    "    texts = [f\"passage: {t}\" for t in texts]\n",
    "    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**inputs)\n",
    "    return mean_pooling(model_output, inputs[\"attention_mask\"]).numpy()\n",
    "\n",
    "def embed_with_sentence_transformer(texts, model):\n",
    "    return model.encode(texts, batch_size=32, show_progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1f11f38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 63/63 [12:36<00:00, 12.01s/it]\n",
      "Batches: 100%|██████████| 16/16 [03:10<00:00, 11.92s/it]\n",
      "Batches: 100%|██████████| 63/63 [01:06<00:00,  1.06s/it]\n",
      "Batches: 100%|██████████| 16/16 [00:16<00:00,  1.04s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# E5 Model\n",
    "e5_tokenizer = AutoTokenizer.from_pretrained(\"intfloat/e5-base-v2\")\n",
    "e5_model = AutoModel.from_pretrained(\"intfloat/e5-base-v2\")\n",
    "\n",
    "# MPNet Model\n",
    "mpnet_model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "\n",
    "# MiniLM Model\n",
    "minilm_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Embed for E5 (Unified)\n",
    "# X_train_e5 = embed_with_e5(X_train, e5_model, e5_tokenizer)\n",
    "# X_test_e5 = embed_with_e5(X_test, e5_model, e5_tokenizer)\n",
    "\n",
    "# Embed for MPNet (Split)\n",
    "X_train_mpnet = embed_with_sentence_transformer(X_train, mpnet_model)\n",
    "X_test_mpnet = embed_with_sentence_transformer(X_test, mpnet_model)\n",
    "\n",
    "# Embed for MiniLM (Split)\n",
    "X_train_minilm = embed_with_sentence_transformer(X_train, minilm_model)\n",
    "X_test_minilm = embed_with_sentence_transformer(X_test, minilm_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "383f6724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Split (MPNet) ---\n",
      "Accuracy: 0.7424547283702213\n",
      "F1 (macro): 0.6748533940736242\n",
      "Classification Report:\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "            ACCOUNTANT       0.82      0.96      0.88        24\n",
      "              ADVOCATE       0.64      0.67      0.65        24\n",
      "           AGRICULTURE       1.00      0.62      0.76        13\n",
      "               APPAREL       0.57      0.21      0.31        19\n",
      "                  ARTS       0.60      0.29      0.39        21\n",
      "            AUTOMOBILE       0.00      0.00      0.00         7\n",
      "              AVIATION       0.79      0.79      0.79        24\n",
      "               BANKING       0.63      0.74      0.68        23\n",
      "                   BPO       0.00      0.00      0.00         4\n",
      "  BUSINESS-DEVELOPMENT       0.92      0.92      0.92        24\n",
      "                  CHEF       0.86      0.79      0.83        24\n",
      "          CONSTRUCTION       0.84      0.73      0.78        22\n",
      "            CONSULTANT       0.71      0.65      0.68        23\n",
      "              DESIGNER       0.80      0.95      0.87        21\n",
      "         DIGITAL-MEDIA       0.87      0.68      0.76        19\n",
      "           ENGINEERING       0.87      0.83      0.85        24\n",
      "               FINANCE       0.88      0.88      0.88        24\n",
      "               FITNESS       0.68      0.57      0.62        23\n",
      "            HEALTHCARE       0.52      0.70      0.59        23\n",
      "                    HR       0.88      1.00      0.94        22\n",
      "INFORMATION-TECHNOLOGY       0.73      0.92      0.81        24\n",
      "      PUBLIC-RELATIONS       0.63      0.77      0.69        22\n",
      "                 SALES       0.68      0.91      0.78        23\n",
      "               TEACHER       0.59      0.95      0.73        20\n",
      "\n",
      "              accuracy                           0.74       497\n",
      "             macro avg       0.69      0.69      0.67       497\n",
      "          weighted avg       0.73      0.74      0.72       497\n",
      "\n",
      "\n",
      "--- Split (MiniLM) ---\n",
      "Accuracy: 0.7183098591549296\n",
      "F1 (macro): 0.6512062829355826\n",
      "Classification Report:\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "            ACCOUNTANT       0.75      0.88      0.81        24\n",
      "              ADVOCATE       0.59      0.71      0.64        24\n",
      "           AGRICULTURE       1.00      0.54      0.70        13\n",
      "               APPAREL       0.44      0.21      0.29        19\n",
      "                  ARTS       0.71      0.24      0.36        21\n",
      "            AUTOMOBILE       0.00      0.00      0.00         7\n",
      "              AVIATION       0.80      0.67      0.73        24\n",
      "               BANKING       0.70      0.70      0.70        23\n",
      "                   BPO       0.00      0.00      0.00         4\n",
      "  BUSINESS-DEVELOPMENT       0.77      0.83      0.80        24\n",
      "                  CHEF       0.95      0.83      0.89        24\n",
      "          CONSTRUCTION       0.81      0.77      0.79        22\n",
      "            CONSULTANT       0.68      0.65      0.67        23\n",
      "              DESIGNER       0.83      0.95      0.89        21\n",
      "         DIGITAL-MEDIA       0.79      0.58      0.67        19\n",
      "           ENGINEERING       0.91      0.88      0.89        24\n",
      "               FINANCE       0.78      0.88      0.82        24\n",
      "               FITNESS       0.57      0.52      0.55        23\n",
      "            HEALTHCARE       0.47      0.70      0.56        23\n",
      "                    HR       0.88      0.95      0.91        22\n",
      "INFORMATION-TECHNOLOGY       0.67      0.92      0.77        24\n",
      "      PUBLIC-RELATIONS       0.60      0.68      0.64        22\n",
      "                 SALES       0.73      0.96      0.83        23\n",
      "               TEACHER       0.62      0.90      0.73        20\n",
      "\n",
      "              accuracy                           0.72       497\n",
      "             macro avg       0.67      0.66      0.65       497\n",
      "          weighted avg       0.71      0.72      0.70       497\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Study\\Level4\\grad project\\VC-management-system\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\Study\\Level4\\grad project\\VC-management-system\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\Study\\Level4\\grad project\\VC-management-system\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\Study\\Level4\\grad project\\VC-management-system\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\Study\\Level4\\grad project\\VC-management-system\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\Study\\Level4\\grad project\\VC-management-system\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "def evaluate_embeddings(X_train, y_train, X_test, y_test, label_map, name=\"Model\"):\n",
    "    clf = LogisticRegression(max_iter=1000)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    print(f\"\\n--- {name} ---\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"F1 (macro):\", f1_score(y_test, y_pred, average=\"macro\"))\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=label_map.values()))\n",
    "\n",
    "# Evaluate both\n",
    "#evaluate_embeddings(X_train_e5, y_train, X_test_e5, y_test, label_map, name=\"Unified (E5)\")\n",
    "evaluate_embeddings(X_train_mpnet, y_train, X_test_mpnet, y_test, label_map, name=\"Split (MPNet)\")\n",
    "evaluate_embeddings(X_train_minilm, y_train, X_test_minilm, y_test, label_map, name=\"Split (MiniLM)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285e1db0",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "First, e5 embedding model needs a lot of memory and we can not afford it to run. Second, there is no need for hybrid embedding models since the f1 scores are relatively close though the mpnet model is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acd6b63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
